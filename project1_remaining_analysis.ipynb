{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPZeQRVvUzyBw09w596Esj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aqu7he/DS-4002-Group-5/blob/main/project1_remaining_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code that conducts the remaining analysis on the data (after sentiment scores have been assigned by VADER)."
      ],
      "metadata": {
        "id": "2QCKC86UkQ12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjgbLWgZkLY-",
        "outputId": "95f8407c-5880-42aa-cde7-aa33fb41e970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.2.2)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "# read in necessary packages\n",
        "! pip install vaderSentiment\n",
        "\n",
        "import vaderSentiment\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in cleaned .csv file\n",
        "filename = r'/content/clean_chiefs_data.csv'\n",
        "chiefs_data = pd.read_csv(filename)\n",
        "print(chiefs_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpMJkuwkksxk",
        "outputId": "1e970e13-02c1-47d9-d43d-287f70c22d32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           date   timestamp  \\\n",
            "0    2023-12-17  1702847139   \n",
            "1    2023-03-15  1678885214   \n",
            "2    2023-12-26  1703559505   \n",
            "3    2023-07-22  1690059620   \n",
            "4    2023-07-04  1688484817   \n",
            "..          ...         ...   \n",
            "194  2024-01-22  1705938051   \n",
            "195  2024-01-30  1706653721   \n",
            "196  2024-01-11  1704992598   \n",
            "197  2023-05-03  1683122345   \n",
            "198  2023-11-12  1699752165   \n",
            "\n",
            "                                                 title  \\\n",
            "0    rice with another stellar performance  catches...   \n",
            "1                            from the dark days to now   \n",
            "2    the chiefs now have the worst turnover differe...   \n",
            "3                 cmon veach please get this deal done   \n",
            "4    didnt think this would be a conversation wed b...   \n",
            "..                                                 ...   \n",
            "194  how about mvs making a couple big catches last...   \n",
            "195  patrick mahomes theres only been like three oc...   \n",
            "196  my son shoveled snow for two days to buy a pla...   \n",
            "197  kctv jackson mahomes arrested accused of aggra...   \n",
            "198         taylors dad has officially been converted    \n",
            "\n",
            "                                                  text         subreddit  \\\n",
            "0    Before this game he needed to average 85 yards...  KansasCityChiefs   \n",
            "1    It\u0019s 2003, Trent Green is under center.. Pries...  KansasCityChiefs   \n",
            "2    With all data showing a turnover lost is -4 po...  KansasCityChiefs   \n",
            "3    Link to full tweet: https://twitter.com/adamsc...  KansasCityChiefs   \n",
            "4                             (And I\u0019m so here for it)  KansasCityChiefs   \n",
            "..                                                 ...               ...   \n",
            "194  Both catches were bobbled a bit but he made a ...  KansasCityChiefs   \n",
            "195  Mahomes confirming that Justin Tucker always t...  KansasCityChiefs   \n",
            "196  My 14 year old son got bored during the snow d...  KansasCityChiefs   \n",
            "197  Stemming from the February incident at a resta...  KansasCityChiefs   \n",
            "198                   The newest chiefs kingdom member  KansasCityChiefs   \n",
            "\n",
            "     comments                                                url  \\\n",
            "0          95  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "1          92  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "2          49  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "3         205  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "4          56  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "..        ...                                                ...   \n",
            "194       150  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "195       196  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "196       110  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "197       611  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "198        76  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "\n",
            "     sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "0           0.283333            After Event          0.5719           Positive  \n",
            "1          -0.150000           Before Event          0.0000            Neutral  \n",
            "2          -1.000000            After Event         -0.6249           Negative  \n",
            "3           0.000000           Before Event          0.3182           Positive  \n",
            "4           0.000000           Before Event          0.0000            Neutral  \n",
            "..               ...                    ...             ...                ...  \n",
            "194         0.000000            After Event          0.0000            Neutral  \n",
            "195         0.142857            After Event          0.0433            Neutral  \n",
            "196         0.000000            After Event          0.0000            Neutral  \n",
            "197         0.500000           Before Event         -0.8020           Negative  \n",
            "198         0.000000            After Event          0.0000            Neutral  \n",
            "\n",
            "[199 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate into before and after\n",
        "chiefs_before = chiefs_data[(chiefs_data['before_after_indicator'] == 'Before Event')]\n",
        "print(chiefs_before)\n",
        "chiefs_after = chiefs_data[(chiefs_data['before_after_indicator'] == 'After Event')]\n",
        "print(chiefs_after)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgMqHNZJlNpt",
        "outputId": "584c5ef2-271e-4f77-be4b-899c45f0a090"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           date   timestamp  \\\n",
            "1    2023-03-15  1678885214   \n",
            "3    2023-07-22  1690059620   \n",
            "4    2023-07-04  1688484817   \n",
            "6    2023-07-14  1689356971   \n",
            "7    2023-02-12  1676211676   \n",
            "..          ...         ...   \n",
            "180  2023-06-16  1686894479   \n",
            "181  2023-02-14  1676387559   \n",
            "190  2023-04-27  1682597872   \n",
            "192  2023-02-12  1676199145   \n",
            "197  2023-05-03  1683122345   \n",
            "\n",
            "                                                 title  \\\n",
            "1                            from the dark days to now   \n",
            "3                 cmon veach please get this deal done   \n",
            "4    didnt think this would be a conversation wed b...   \n",
            "6                        patrick mahomes fascinates me   \n",
            "7    before the game and whatever happens after win...   \n",
            "..                                                 ...   \n",
            "180  kansas city chiefs the moment weve all been wa...   \n",
            "181  this was the greatest chiefs season of alltime...   \n",
            "190                                    years ago today   \n",
            "192  wake the god damn fuck up its the motherfuckin...   \n",
            "197  kctv jackson mahomes arrested accused of aggra...   \n",
            "\n",
            "                                                  text         subreddit  \\\n",
            "1    It\u0019s 2003, Trent Green is under center.. Pries...  KansasCityChiefs   \n",
            "3    Link to full tweet: https://twitter.com/adamsc...  KansasCityChiefs   \n",
            "4                             (And I\u0019m so here for it)  KansasCityChiefs   \n",
            "6    Colts fan coming in peace. \\n\\nWatching \u001cQuart...  KansasCityChiefs   \n",
            "7    I'm binging Hard Knocks 2007. Where our QB bat...  KansasCityChiefs   \n",
            "..                                                 ...               ...   \n",
            "180  https://twitter.com/Chiefs/status/166954098638...  KansasCityChiefs   \n",
            "181  Maybe an argument for 2020 since we finally go...  KansasCityChiefs   \n",
            "190                                       Boy howdy...  KansasCityChiefs   \n",
            "192  GOOOOOOOOOOOOD MORNING CHIEFS KINGDOM! AFTER B...  KansasCityChiefs   \n",
            "197  Stemming from the February incident at a resta...  KansasCityChiefs   \n",
            "\n",
            "     comments                                                url  \\\n",
            "1          92  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "3         205  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "4          56  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "6          94  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "7          23  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "..        ...                                                ...   \n",
            "180        62  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "181       200  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "190       105  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "192       493  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "197       611  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "\n",
            "     sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "1          -0.150000           Before Event          0.0000            Neutral  \n",
            "3           0.000000           Before Event          0.3182           Positive  \n",
            "4           0.000000           Before Event          0.0000            Neutral  \n",
            "6           0.000000           Before Event          0.4588           Positive  \n",
            "7           0.200000           Before Event          0.7003           Positive  \n",
            "..               ...                    ...             ...                ...  \n",
            "180         0.000000           Before Event          0.0000            Neutral  \n",
            "181         0.642857           Before Event          0.6369           Positive  \n",
            "190         0.000000           Before Event          0.0000            Neutral  \n",
            "192        -0.033333           Before Event         -0.6124           Negative  \n",
            "197         0.500000           Before Event         -0.8020           Negative  \n",
            "\n",
            "[61 rows x 11 columns]\n",
            "           date   timestamp  \\\n",
            "0    2023-12-17  1702847139   \n",
            "2    2023-12-26  1703559505   \n",
            "5    2024-01-28  1706483564   \n",
            "8    2024-01-28  1706484032   \n",
            "9    2024-01-29  1706567046   \n",
            "..          ...         ...   \n",
            "193  2024-01-24  1706124282   \n",
            "194  2024-01-22  1705938051   \n",
            "195  2024-01-30  1706653721   \n",
            "196  2024-01-11  1704992598   \n",
            "198  2023-11-12  1699752165   \n",
            "\n",
            "                                                 title  \\\n",
            "0    rice with another stellar performance  catches...   \n",
            "2    the chiefs now have the worst turnover differe...   \n",
            "5    post game thread kansas city chiefs at baltimo...   \n",
            "8    lets give it up for  came up huge in a tough s...   \n",
            "9                            edge room needs some help   \n",
            "..                                                 ...   \n",
            "193                            well this is just gross   \n",
            "194  how about mvs making a couple big catches last...   \n",
            "195  patrick mahomes theres only been like three oc...   \n",
            "196  my son shoveled snow for two days to buy a pla...   \n",
            "198         taylors dad has officially been converted    \n",
            "\n",
            "                                                  text         subreddit  \\\n",
            "0    Before this game he needed to average 85 yards...  KansasCityChiefs   \n",
            "2    With all data showing a turnover lost is -4 po...  KansasCityChiefs   \n",
            "5    #Kansas City Chiefs at Baltimore Ravens\\n\\n[ES...  KansasCityChiefs   \n",
            "8           Helluva game from our backup left guard!!!  KansasCityChiefs   \n",
            "9    I was against this 4 weeks ago but now with Om...  KansasCityChiefs   \n",
            "..                                                 ...               ...   \n",
            "193                buffalo keeping it classy as always  KansasCityChiefs   \n",
            "194  Both catches were bobbled a bit but he made a ...  KansasCityChiefs   \n",
            "195  Mahomes confirming that Justin Tucker always t...  KansasCityChiefs   \n",
            "196  My 14 year old son got bored during the snow d...  KansasCityChiefs   \n",
            "198                   The newest chiefs kingdom member  KansasCityChiefs   \n",
            "\n",
            "     comments                                                url  \\\n",
            "0          95  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "2          49  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "5        1154  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "8           8  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "9          61  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "..        ...                                                ...   \n",
            "193       646  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "194       150  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "195       196  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "196       110  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "198        76  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "\n",
            "     sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "0           0.283333            After Event          0.5719           Positive  \n",
            "2          -1.000000            After Event         -0.6249           Negative  \n",
            "5          -0.400000            After Event          0.0000            Neutral  \n",
            "8           0.005556            After Event          0.2023           Positive  \n",
            "9           0.000000            After Event          0.4019           Positive  \n",
            "..               ...                    ...             ...                ...  \n",
            "193         0.000000            After Event         -0.2500           Negative  \n",
            "194         0.000000            After Event          0.0000            Neutral  \n",
            "195         0.142857            After Event          0.0433            Neutral  \n",
            "196         0.000000            After Event          0.0000            Neutral  \n",
            "198         0.000000            After Event          0.0000            Neutral  \n",
            "\n",
            "[138 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up information for conducting t-test\n",
        "# import required package\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "t-4NQwbYmZ3X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# based on previous slices of dataframe, extract compound scores only\n",
        "before_scores = chiefs_before['compound_score']\n",
        "after_scores = chiefs_after['compound_score']\n",
        "\n",
        "print('Mean Sentiments Before Taylor: ' + str(before_scores.mean()))\n",
        "print('Mean Sentiments After Taylor: ' + str(after_scores.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QitgApqpmwAC",
        "outputId": "0051d5d7-3c0f-4ff3-91fb-d2432d1de7bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Sentiments Before Taylor: 0.1010344262295082\n",
            "Mean Sentiments After Taylor: 0.07020434782608696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretty evident that we will fail to reject null, but gonna run the t-test anyways\n",
        "stats.ttest_ind(after_scores, before_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pooQLryPnR7K",
        "outputId": "5653a4e5-13a0-4721-8be9-119ed7cd5625"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=-0.5567575722172928, pvalue=0.5783250097260251, df=197.0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no need to divide by 2. T-statistic is negative, so sample mean less than H0\n",
        "# Results not statistically significant, so we fail to reject the null.\n",
        "# Given small size of our dataset, I think that the shorter timeframe test will be even less successful.\n",
        "# But I will see the analysis plan to the end.\n",
        "\n",
        "# further constrain dataset, using timestamp b/c it's an integer\n",
        "chiefs_before['date'] = pd.to_datetime(chiefs_before['date'])\n",
        "\n",
        "# Specified date\n",
        "specified_date = pd.to_datetime(\"2023-09-17\")\n",
        "\n",
        "chiefs_before_narrow = chiefs_before[chiefs_before['date'] >= specified_date]\n",
        "print(chiefs_before_narrow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MLbJxUboI7D",
        "outputId": "c057068d-397a-4dfa-c32e-f9cf6d684712"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date   timestamp                                  title  \\\n",
            "17 2023-09-17  1694994662  broncos chargers and raiders all lose   \n",
            "38 2023-09-17  1694987735                      the good old days   \n",
            "83 2023-09-21  1695301319                happy retirement dr ldt   \n",
            "\n",
            "                                                 text         subreddit  \\\n",
            "17  Chargers and broncos both in devastating fashi...  KansasCityChiefs   \n",
            "38  I hope Taylor turns it around, but it makes me...  KansasCityChiefs   \n",
            "83  I still wish they let him add M.D. on his jersey.  KansasCityChiefs   \n",
            "\n",
            "    comments                                                url  \\\n",
            "17        86  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "38        16  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "83        34  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "\n",
            "    sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "17              0.0           Before Event         -0.4019           Negative  \n",
            "38              0.4           Before Event          0.4404           Positive  \n",
            "83              0.8           Before Event          0.5719           Positive  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-696ccc20db22>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chiefs_before['date'] = pd.to_datetime(chiefs_before['date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract URLs\n",
        "url_list = chiefs_before_narrow['url'].tolist()\n",
        "\n",
        "###\n",
        "\n",
        "# not part of final product"
      ],
      "metadata": {
        "id": "_BAgGp03_a5c"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now for the opposite\n",
        "\n",
        "chiefs_after['date'] = pd.to_datetime(chiefs_after['date'])\n",
        "\n",
        "# Specified date\n",
        "specified_date = pd.to_datetime(\"2023-10-01\")\n",
        "\n",
        "chiefs_after_narrow = chiefs_after.loc[chiefs_after['date'] <= specified_date]\n",
        "print(chiefs_after_narrow)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqSYAneCwvbJ",
        "outputId": "28c504a9-7544-4d99-f6e7-937d449674c3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date   timestamp                                              title  \\\n",
            "40 2023-09-27  1695841670  i wasnt sure id ever say this but this is a ch...   \n",
            "75 2023-09-27  1695823758  chiefs fans and arrowhead in general are very ...   \n",
            "\n",
            "                                                 text         subreddit  \\\n",
            "40  Top 5 in the NFL. The defense is stout and loc...  KansasCityChiefs   \n",
            "75  As the title states, you guys are very welcomi...  KansasCityChiefs   \n",
            "\n",
            "    comments                                                url  \\\n",
            "40        69  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "75        55  https://www.reddit.com/r/KansasCityChiefs/comm...   \n",
            "\n",
            "    sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "40             0.50            After Event          0.6926           Positive  \n",
            "75             0.35            After Event          0.7693           Positive  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-4fd9f017f0b0>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chiefs_after['date'] = pd.to_datetime(chiefs_after['date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cHU46UA_vZZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url_list.append(chiefs_after_narrow['url'].tolist())\n",
        "# print(url_list)\n",
        "\n",
        "###\n",
        "\n",
        "# not part of final product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArfT7wtBAZZG",
        "outputId": "e844d55d-b486-4295-e688-ac9e4c1cf35f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.reddit.com/r/KansasCityChiefs/comments/16lg2n2/broncos_chargers_and_raiders_all_lose/', 'https://www.reddit.com/r/KansasCityChiefs/comments/16ldez5/the_good_old_days/', 'https://www.reddit.com/r/KansasCityChiefs/comments/16ofd00/happy_retirement_dr_ldt/', ['https://www.reddit.com/r/KansasCityChiefs/comments/16tt073/i_wasnt_sure_id_ever_say_this_but_this_is_a/', 'https://www.reddit.com/r/KansasCityChiefs/comments/16tlmwx/chiefs_fans_and_arrowhead_in_general_are_very/']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only 5 observations\n",
        "# will run significance test, just for fun\n",
        "\n",
        "before_scores = chiefs_before_narrow['compound_score']\n",
        "after_scores = chiefs_after_narrow['compound_score']"
      ],
      "metadata": {
        "id": "ZzaZDzo6xEDj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = stats.ttest_ind(after_scores, before_scores)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapZ-TI3xinf",
        "outputId": "8ff9c6b5-dfc3-45a3-a40a-0b539d1d31fb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TtestResult(statistic=1.3358756736084882, pvalue=0.2738892008255432, df=3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eO03c_i6xnQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test statistic is positive. However, the p-value is 0.27, above the treshhold for significance of 0.05. This is unsurprising given the small sample size."
      ],
      "metadata": {
        "id": "fhu-BbjA4qg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what if we pull all the comments from those threads?\n",
        "# now need to do sentiment scoring for all that\n",
        "\n",
        "###\n",
        "\n",
        "# anything below this is not part of the final product\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# List of example texts to analyze\n",
        "data = pd.read_csv('/content/chiefs_data_narrow.csv')\n",
        "# data = pd.read_csv('chiefs_data_narrow.csv')\n",
        "\n",
        "text_column= 'comment'\n",
        "\n",
        "def get_sentiment(comment):\n",
        "    analysis = TextBlob(str(comment))\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "# Apply the function to the text column and create a new column for sentiment scores\n",
        "data['sentiment_score'] = data[text_column].apply(get_sentiment)\n",
        "\n",
        "# Display the DataFrame with sentiment scores\n",
        "print(data[['comment', 'sentiment_score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrlBxRhiStxM",
        "outputId": "f30fc8fb-d90f-43fe-de18-82fa9642d609"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               comment  sentiment_score\n",
            "0    You can take EB out of the AFCW, but he still ...         0.000000\n",
            "1    I want EB to crush it in Washington as a \u001cfuck...         0.066667\n",
            "2    How Staley still has a HC job is absolutely ba...         0.200000\n",
            "3    Bottom 5 coach in the league.\\r\\n\\r\\nSomehow t...         0.400000\n",
            "4    McDaniels is cool though.  You don't have to l...         0.350000\n",
            "..                                                 ...              ...\n",
            "245  The chappas were a treat I'm sure but nothing ...         0.271429\n",
            "246                           What a great experience.         0.800000\n",
            "247  Thank you for sharing this.  I enjoyed reading...         0.500000\n",
            "248  I\u0019ve been a visitor to every game I\u0019ve gone to...        -0.325000\n",
            "249  Hey man, happy to have you and glad you had a ...         0.666667\n",
            "\n",
            "[250 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Specified date\n",
        "specified_date = pd.to_datetime(\"2023-09-24\")\n",
        "\n",
        "# Add a new column 'before_after_indicator' based on the comparison with the specified date\n",
        "data['before_after_indicator'] = np.where(data['date'] < specified_date, 'Before Event', 'After Event')\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pydcxZMkTCu1",
        "outputId": "895235e6-c823-49b3-e728-b147a4857f63"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   url               author  \\\n",
            "0    https://www.reddit.com/r/KansasCityChiefs/comm...         FingerTampon   \n",
            "1    https://www.reddit.com/r/KansasCityChiefs/comm...          Scaryclouds   \n",
            "2    https://www.reddit.com/r/KansasCityChiefs/comm...             revnasty   \n",
            "3    https://www.reddit.com/r/KansasCityChiefs/comm...          Scaryclouds   \n",
            "4    https://www.reddit.com/r/KansasCityChiefs/comm...  Pineappletittyworms   \n",
            "..                                                 ...                  ...   \n",
            "245  https://www.reddit.com/r/KansasCityChiefs/comm...           chowder007   \n",
            "246  https://www.reddit.com/r/KansasCityChiefs/comm...          Royals-2015   \n",
            "247  https://www.reddit.com/r/KansasCityChiefs/comm...          Eclipse1876   \n",
            "248  https://www.reddit.com/r/KansasCityChiefs/comm...   Medium-Salary-2799   \n",
            "249  https://www.reddit.com/r/KansasCityChiefs/comm...             Vyuvarax   \n",
            "\n",
            "          date   timestamp  score  upvotes  downvotes  golds  \\\n",
            "0   2023-09-18  1694995606    171      171          0      0   \n",
            "1   2023-09-18  1695002323     63       63          0      0   \n",
            "2   2023-09-18  1695059325      5        5          0      0   \n",
            "3   2023-09-18  1695059891      7        7          0      0   \n",
            "4   2023-09-18  1695010123     -7       -7          0      0   \n",
            "..         ...         ...    ...      ...        ...    ...   \n",
            "245 2023-09-28  1695871937      2        2          0      0   \n",
            "246 2023-09-28  1695937925      2        2          0      0   \n",
            "247 2023-09-29  1695956205      2        2          0      0   \n",
            "248 2023-09-29  1696000816      2        2          0      0   \n",
            "249 2023-09-27  1695825987      3        3          0      0   \n",
            "\n",
            "                                               comment comment_id  \\\n",
            "0    You can take EB out of the AFCW, but he still ...          1   \n",
            "1    I want EB to crush it in Washington as a \u001cfuck...        1_1   \n",
            "2    How Staley still has a HC job is absolutely ba...      1_1_1   \n",
            "3    Bottom 5 coach in the league.\\r\\n\\r\\nSomehow t...    1_1_1_1   \n",
            "4    McDaniels is cool though.  You don't have to l...      1_1_2   \n",
            "..                                                 ...        ...   \n",
            "245  The chappas were a treat I'm sure but nothing ...         24   \n",
            "246                           What a great experience.         25   \n",
            "247  Thank you for sharing this.  I enjoyed reading...         26   \n",
            "248  I\u0019ve been a visitor to every game I\u0019ve gone to...         27   \n",
            "249  Hey man, happy to have you and glad you had a ...         28   \n",
            "\n",
            "     sentiment_score before_after_indicator  \n",
            "0           0.000000           Before Event  \n",
            "1           0.066667           Before Event  \n",
            "2           0.200000           Before Event  \n",
            "3           0.400000           Before Event  \n",
            "4           0.350000           Before Event  \n",
            "..               ...                    ...  \n",
            "245         0.271429            After Event  \n",
            "246         0.800000            After Event  \n",
            "247         0.500000            After Event  \n",
            "248        -0.325000            After Event  \n",
            "249         0.666667            After Event  \n",
            "\n",
            "[250 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "data['comment'] = data['comment'].astype(str)\n",
        "\n",
        "# Apply sentiment analysis and calculate compound score\n",
        "data['compound_score'] = data['comment'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "\n",
        "# Specify a threshold for categorizing as positive or negative\n",
        "threshold = 0.05\n",
        "\n",
        "# Categorize sentiment as positive, negative, or neutral based on the compound score\n",
        "data['sentiment_category'] = pd.cut(data['compound_score'], bins=[float('-inf'), -threshold, threshold, float('inf')],\n",
        "                                    labels=['Negative', 'Neutral', 'Positive'], include_lowest=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETkA1-H8TK0y",
        "outputId": "b1e68323-b772-4696-8573-7f13aec142dd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate into before and after\n",
        "chiefs_before_n = data[(data['before_after_indicator'] == 'Before Event')]\n",
        "print(chiefs_before_n)\n",
        "chiefs_after_n = data[(data['before_after_indicator'] == 'After Event')]\n",
        "print(chiefs_after_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WR-HfUiTgbK",
        "outputId": "2fe10830-21d6-41c5-8a10-6045ff520a26"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   url               author  \\\n",
            "0    https://www.reddit.com/r/KansasCityChiefs/comm...         FingerTampon   \n",
            "1    https://www.reddit.com/r/KansasCityChiefs/comm...          Scaryclouds   \n",
            "2    https://www.reddit.com/r/KansasCityChiefs/comm...             revnasty   \n",
            "3    https://www.reddit.com/r/KansasCityChiefs/comm...          Scaryclouds   \n",
            "4    https://www.reddit.com/r/KansasCityChiefs/comm...  Pineappletittyworms   \n",
            "..                                                 ...                  ...   \n",
            "128  https://www.reddit.com/r/KansasCityChiefs/comm...            pinniped1   \n",
            "129  https://www.reddit.com/r/KansasCityChiefs/comm...        ChukarTheFker   \n",
            "130  https://www.reddit.com/r/KansasCityChiefs/comm...        Trashpanda779   \n",
            "131  https://www.reddit.com/r/KansasCityChiefs/comm...        jacksonross33   \n",
            "132  https://www.reddit.com/r/KansasCityChiefs/comm...              CJSki93   \n",
            "\n",
            "          date   timestamp  score  upvotes  downvotes  golds  \\\n",
            "0   2023-09-18  1694995606    171      171          0      0   \n",
            "1   2023-09-18  1695002323     63       63          0      0   \n",
            "2   2023-09-18  1695059325      5        5          0      0   \n",
            "3   2023-09-18  1695059891      7        7          0      0   \n",
            "4   2023-09-18  1695010123     -7       -7          0      0   \n",
            "..         ...         ...    ...      ...        ...    ...   \n",
            "128 2023-09-21  1695320214      3        3          0      0   \n",
            "129 2023-09-22  1695341728     -8       -8          0      0   \n",
            "130 2023-09-22  1695353312      4        4          0      0   \n",
            "131 2023-09-23  1695444149      1        1          0      0   \n",
            "132 2023-09-21  1695339541      1        1          0      0   \n",
            "\n",
            "                                               comment comment_id  \\\n",
            "0    You can take EB out of the AFCW, but he still ...          1   \n",
            "1    I want EB to crush it in Washington as a \u001cfuck...        1_1   \n",
            "2    How Staley still has a HC job is absolutely ba...      1_1_1   \n",
            "3    Bottom 5 coach in the league.\\r\\n\\r\\nSomehow t...    1_1_1_1   \n",
            "4    McDaniels is cool though.  You don't have to l...      1_1_2   \n",
            "..                                                 ...        ...   \n",
            "128  Good for him.\\r\\n\\r\\nMade it to the top, won a...         12   \n",
            "129  Pretty disappointed that he sat out a season f...         13   \n",
            "130                     bro what. gtfo with this shit.       13_1   \n",
            "131                  To be an *orderly*. Not a doctor.       13_2   \n",
            "132  Was really hoping he\u0019d have at least returned ...         14   \n",
            "\n",
            "     sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "0           0.000000           Before Event         -0.5023           Negative  \n",
            "1           0.066667           Before Event          0.5858           Positive  \n",
            "2           0.200000           Before Event          0.0000            Neutral  \n",
            "3           0.400000           Before Event         -0.4678           Negative  \n",
            "4           0.350000           Before Event          0.0245            Neutral  \n",
            "..               ...                    ...             ...                ...  \n",
            "128         0.310000           Before Event          0.8955           Positive  \n",
            "129        -0.250000           Before Event          0.0258            Neutral  \n",
            "130        -0.200000           Before Event         -0.6428           Negative  \n",
            "131         0.000000           Before Event          0.0000            Neutral  \n",
            "132         0.133333           Before Event          0.4754           Positive  \n",
            "\n",
            "[133 rows x 14 columns]\n",
            "                                                   url               author  \\\n",
            "133  https://www.reddit.com/r/KansasCityChiefs/comm...       heliostraveler   \n",
            "134  https://www.reddit.com/r/KansasCityChiefs/comm...       Gabbagoonumba3   \n",
            "135  https://www.reddit.com/r/KansasCityChiefs/comm...       apiratewithadd   \n",
            "136  https://www.reddit.com/r/KansasCityChiefs/comm...             Dreadsbo   \n",
            "137  https://www.reddit.com/r/KansasCityChiefs/comm...  thehomelessaviation   \n",
            "..                                                 ...                  ...   \n",
            "245  https://www.reddit.com/r/KansasCityChiefs/comm...           chowder007   \n",
            "246  https://www.reddit.com/r/KansasCityChiefs/comm...          Royals-2015   \n",
            "247  https://www.reddit.com/r/KansasCityChiefs/comm...          Eclipse1876   \n",
            "248  https://www.reddit.com/r/KansasCityChiefs/comm...   Medium-Salary-2799   \n",
            "249  https://www.reddit.com/r/KansasCityChiefs/comm...             Vyuvarax   \n",
            "\n",
            "          date   timestamp  score  upvotes  downvotes  golds  \\\n",
            "133 2023-09-27  1695842269     82       82          0      0   \n",
            "134 2023-09-27  1695850105     34       34          0      0   \n",
            "135 2023-09-28  1695911947      1        1          0      0   \n",
            "136 2023-09-28  1695869769      7        7          0      0   \n",
            "137 2023-09-27  1695849859     13       13          0      0   \n",
            "..         ...         ...    ...      ...        ...    ...   \n",
            "245 2023-09-28  1695871937      2        2          0      0   \n",
            "246 2023-09-28  1695937925      2        2          0      0   \n",
            "247 2023-09-29  1695956205      2        2          0      0   \n",
            "248 2023-09-29  1696000816      2        2          0      0   \n",
            "249 2023-09-27  1695825987      3        3          0      0   \n",
            "\n",
            "                                               comment comment_id  \\\n",
            "133  They\u0019ve faced good offenses too. Two out of th...          1   \n",
            "134  I\u0019m big on yards per game because points don\u0019t...        1_1   \n",
            "135                       Skyy doesn\u0019t play defense =\u0002      1_1_1   \n",
            "136  Our defense is so good this year that I though...        1_2   \n",
            "137  I don\u0019t think the Jags offense is good. They\u0019r...        1_3   \n",
            "..                                                 ...        ...   \n",
            "245  The chappas were a treat I'm sure but nothing ...         24   \n",
            "246                           What a great experience.         25   \n",
            "247  Thank you for sharing this.  I enjoyed reading...         26   \n",
            "248  I\u0019ve been a visitor to every game I\u0019ve gone to...         27   \n",
            "249  Hey man, happy to have you and glad you had a ...         28   \n",
            "\n",
            "     sentiment_score before_after_indicator  compound_score sentiment_category  \n",
            "133     5.551115e-17            After Event         -0.4767           Negative  \n",
            "134     3.171875e-01            After Event          0.8832           Positive  \n",
            "135     0.000000e+00            After Event          0.4404           Positive  \n",
            "136     7.000000e-01            After Event          0.5709           Positive  \n",
            "137     3.500000e-01            After Event          0.7003           Positive  \n",
            "..               ...                    ...             ...                ...  \n",
            "245     2.714286e-01            After Event          0.5951           Positive  \n",
            "246     8.000000e-01            After Event          0.6249           Positive  \n",
            "247     5.000000e-01            After Event          0.8472           Positive  \n",
            "248    -3.250000e-01            After Event          0.0000            Neutral  \n",
            "249     6.666667e-01            After Event          0.8934           Positive  \n",
            "\n",
            "[117 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# based on previous slices of dataframe, extract compound scores only\n",
        "before_scores_n = chiefs_before_n['compound_score']\n",
        "after_scores_n = chiefs_after_n['compound_score']\n",
        "\n",
        "print('Mean Sentiments Before Taylor: ' + str(before_scores_n.mean()))\n",
        "print('Mean Sentiments After Taylor: ' + str(after_scores_n.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RwyrLBOTufa",
        "outputId": "f97ea783-2a17-4b53-d7b5-a22864d1cf0b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Sentiments Before Taylor: 0.2275195488721804\n",
            "Mean Sentiments After Taylor: 0.34754444444444443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats.ttest_ind(after_scores_n, before_scores_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCV9byziT8EW",
        "outputId": "5aeb9ece-f457-401b-8416-559e92eeb84d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=2.0458353973451775, pvalue=0.04182755115094874, df=248.0)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is interesting, but I think unfortunately it's outside of the scope of our analysis plan. It wouldn't be right to include it. However, something to note for the write-up: if anyone were to replicate this, it would make a lot more sense to have a narrower window of data collection. You could manually scrape the 20 top thread URLs from 9/17-9/31 and then run the R script using get_thread_content. Than, you could conduct sentiment analysis on the comment text responses. As you can see, we got a statistically significant increase in compound sentiment scores using just the comments scraped from 5 threads."
      ],
      "metadata": {
        "id": "gBC_QD7oWHTW"
      }
    }
  ]
}