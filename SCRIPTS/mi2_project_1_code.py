# -*- coding: utf-8 -*-
"""MI2-Project 1 Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k7kX4YmNJ9CVWCqjKK4S5VWoymsSt3HZ
"""

!pip install vaderSentiment

import vaderSentiment
import pandas as pd
import matplotlib.pyplot as plt
from textblob import TextBlob
import numpy as np
import seaborn as sns
from wordcloud import WordCloud

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

"""neg: the negative sentiment score (between 0 and 1)

neu: the neutral sentiment score (between 0 and 1)

pos: the positive sentiment score (between 0 and 1)

compound: the overall sentiment score (between -1 and 1)
"""

analyzer = SentimentIntensityAnalyzer()

# List of example texts to analyze
data = pd.read_csv('chiefs_data.csv')


text_column= 'title'

def get_sentiment(title):
    analysis = TextBlob(str(title))
    return analysis.sentiment.polarity

# Apply the function to the text column and create a new column for sentiment scores
data['sentiment_score'] = data[text_column].apply(get_sentiment)

# Display the DataFrame with sentiment scores
print(data[['title', 'sentiment_score']])

sentiment_counts = pd.cut(data['sentiment_score'], bins=3, labels=['Negative', 'Neutral', 'Positive']).value_counts()

# Plot the sentiments
plt.bar(sentiment_counts.index, sentiment_counts.values)
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Sentiment Analysis')
plt.show()

# Print the number of counts for each sentiment
for sentiment, count in sentiment_counts.items():
    print(f"{sentiment}: {count}")

data['date'] = pd.to_datetime(data['date'])

# Specified date
specified_date = pd.to_datetime("2023-09-24")

# Add a new column 'before_after_indicator' based on the comparison with the specified date
data['before_after_indicator'] = np.where(data['date'] < specified_date, 'Before Event', 'After Event')

# Display the updated DataFrame
print(data)

plt.figure(figsize=(10, 6))
sns.boxplot(x='before_after_indicator', y='sentiment_score', data=data, palette=["blue", "orange"])
plt.title("Boxplot of Sentiment Scores Before and After Event")
plt.xlabel("Before or After Indicator")
plt.ylabel("Sentiment Score")
plt.show()

avg_sentiment = data.groupby('before_after_indicator')['sentiment_score'].mean().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(x='before_after_indicator', y='sentiment_score', data=avg_sentiment, palette=["blue", "orange"])
plt.title("Average Sentiment Before and After Event")
plt.xlabel("Before of After Indicator")
plt.ylabel("Average Sentiment")
plt.show()

!pip install nltk seaborn
import matplotlib.pyplot as plt
import nltk
nltk.download('vader_lexicon')

from nltk.sentiment import SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()
plt.figure(figsize=(12, 8))

plt.subplot(3, 3, 8)
before_event_words = ' '.join(data[data['before_after_indicator'] == 'Before Event']['title'].astype(str))
wordcloud_before_event = WordCloud(min_word_length=3, width=800, height=400, background_color="white").generate(before_event_words)
plt.imshow(wordcloud_before_event, interpolation='bilinear')
plt.title("Word Cloud - Before Event")
plt.axis('off')

# 9. Word Cloud - After Event
plt.subplot(3, 3, 9)
after_event_words = ' '.join(data[data['before_after_indicator'] == 'After Event']['title'].astype(str))
wordcloud_after_event = WordCloud(min_word_length=3, width=800, height=400, background_color="white").generate(after_event_words)
plt.imshow(wordcloud_after_event, interpolation='bilinear')
plt.title("Word Cloud - After Event")
plt.axis('off')

data['title'] = data['title'].astype(str)

# Apply sentiment analysis and calculate compound score
data['compound_score'] = data['title'].apply(lambda x: sia.polarity_scores(x)['compound'])

# Specify a threshold for categorizing as positive or negative
threshold = 0.05

# Categorize sentiment as positive, negative, or neutral based on the compound score
data['sentiment_category'] = pd.cut(data['compound_score'], bins=[float('-inf'), -threshold, threshold, float('inf')],
                                    labels=['Negative', 'Neutral', 'Positive'], include_lowest=True)

# Plotting the count of sentiment categories
plt.subplot(3, 3, 6)
ax = sns.countplot(x='sentiment_category', hue='before_after_indicator', data=data, palette=["blue", "orange"])
plt.title("Sentiment Categories Before and After")

# Rotate x-axis labels
plt.xticks(rotation=45, ha="right")  # Adjust the rotation angle as needed

# Adjust the legend position
plt.legend(title='Before/After Indicator', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.show()

cleaned_text_column = data.dropna(subset=['text'], how='any')
print(cleaned_text_column)

analyzer = SentimentIntensityAnalyzer()

# List of example texts to analyze
data = pd.read_csv('chiefs_data.csv')

data = data.dropna()

text_column= 'text'

def get_sentiment(text):
    analysis = TextBlob(str(text))
    return analysis.sentiment.polarity

# Apply the function to the text column and create a new column for sentiment scores
data['sentiment_score'] = data[text_column].apply(get_sentiment)

# Display the DataFrame with sentiment scores
print(data[['text', 'sentiment_score']])

sentiment_counts = pd.cut(data['sentiment_score'], bins=3, labels=['Negative', 'Neutral', 'Positive']).value_counts()

# Plot the sentiments
plt.bar(sentiment_counts.index, sentiment_counts.values)
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Sentiment Analysis')
plt.show()

# Print the number of counts for each sentiment
for sentiment, count in sentiment_counts.items():
    print(f"{sentiment}: {count}")
